{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Quark Quark is a python HFT trading / testing platform. Quark is designed as a factor driven trading platform, which - Can design, build, test, validate fit and ensemble the factors. - Generates trade signal with the factor values. - Handles market data and orders, providing position management. - Ensures logic / code consistency between live-production and backtesting. - Can be applied to trading stocks, stock indices, derivatives, etc. Function Data Processing Quark collect lv2 data stream. - The market data is fed into a MarketDataService ( MDS ). - Multiple FactorMonitor are registered at MDS , each representing a factor. - Utilizing multiprocessing and shared memory to achieve low latency and high performance. - Market data processing follows a NO-COPY, No-ALTERATION principle. Factor Generation For each MarketDataMonitor, the strategy collect its signal (factor values) on a given interval. - Use .value property of the monitor to collect generated factor. - The factor value must be a float, or a dict of float. - A MonitorManager is provided to collect signal from other processes. - Collected factor values are logged by a metric module, for decision-making and other future usage such as training, reviewing. Fitting With the collected factor values, the Calibration module provides several fitting algos for different prediction targets. By default, a general linear module with bootstrap is provided. Several prediction targets are also provided, see prediction target . Trade Decision Based on the collected signal and current position / balance, the decision core is to make a trade decision (signal). By default, the strategy is using a dummy core, so that no trade action can be triggered without proper initialization. In production mode, the dummy core can be Override by a real decision core, like a MajorityDecisionCore.","title":"Home"},{"location":"#welcome-to-quark","text":"Quark is a python HFT trading / testing platform. Quark is designed as a factor driven trading platform, which - Can design, build, test, validate fit and ensemble the factors. - Generates trade signal with the factor values. - Handles market data and orders, providing position management. - Ensures logic / code consistency between live-production and backtesting. - Can be applied to trading stocks, stock indices, derivatives, etc.","title":"Welcome to Quark"},{"location":"#function","text":"","title":"Function"},{"location":"#data-processing","text":"Quark collect lv2 data stream. - The market data is fed into a MarketDataService ( MDS ). - Multiple FactorMonitor are registered at MDS , each representing a factor. - Utilizing multiprocessing and shared memory to achieve low latency and high performance. - Market data processing follows a NO-COPY, No-ALTERATION principle.","title":"Data Processing"},{"location":"#factor-generation","text":"For each MarketDataMonitor, the strategy collect its signal (factor values) on a given interval. - Use .value property of the monitor to collect generated factor. - The factor value must be a float, or a dict of float. - A MonitorManager is provided to collect signal from other processes. - Collected factor values are logged by a metric module, for decision-making and other future usage such as training, reviewing.","title":"Factor Generation"},{"location":"#fitting","text":"With the collected factor values, the Calibration module provides several fitting algos for different prediction targets. By default, a general linear module with bootstrap is provided. Several prediction targets are also provided, see prediction target .","title":"Fitting"},{"location":"#trade-decision","text":"Based on the collected signal and current position / balance, the decision core is to make a trade decision (signal). By default, the strategy is using a dummy core, so that no trade action can be triggered without proper initialization. In production mode, the dummy core can be Override by a real decision core, like a MajorityDecisionCore.","title":"Trade Decision"},{"location":"factor/data_fields/","text":"Available data fields There are four frequently used subclass of MarketData . - TickData - TransactionData | TradeData - OrderData - OrderBook TickData Represents tick data for a specific ticker. Properties : - ticker : str The ticker symbol for the tick data. - timestamp : float The timestamp of the tick data - bid : list[list[float | int]] | None A list of bid prices and volumes. Optional, used to build the order book. - ask : list[list[float | int]] | None A list of ask prices and volumes. Optional, used to build the order book. - level_2 : OrderBook | None The level 2 order book created from the bid and ask data. - order_book : OrderBook | None Alias for level_2 . - last_price : float The last traded price. - bid_price : float | None The bid1 price. - ask_price : float | None The ask1 price. - bid_volume : float | None The bid1 volume. - ask_volume : float | None The ask1 volume. - total_traded_volume : float The total traded volume, accumulated from opening. - total_traded_notional : float The total traded notional value, accumulated from opening. - total_trade_count : float The total number of trades, accumulated from opening. - mid_price : float The midpoint price calculated as the average of bid and ask prices. - market_price : float The last traded price. TransactionData | TradeData TransactionData represents transaction data for a specific ticker. TradeData allows initialization with trade_price instead of price and trade_volume instead of volume . It provides additional alias properties for these alternate names. SZ market provide canceling in TradeData with price , notional , side.sign , either buy_id or sell_id = 0, FilterMode.no_cancel is used to filter canceling. Properties : - ticker : str The ticker symbol for the transaction data. - timestamp : float The timestamp of the transaction data. - price : float The price at which the transaction occurred. - volume : float | None The volume of the transaction. - side : TransactionSide The side of the transaction (buy, sell or cancel, side.sign 1, -1, 0). - multiplier : float The multiplier for the transaction. - transaction_id : int | str | None The identifier for the transaction. - buy_id : int | str | None The identifier for the buying transaction. - sell_id : int | str | None The identifier for the selling transaction. - notional : float The notional value of the transaction. - market_price : float Alias for price . - flow : float The flow of the transaction, calculated as side.sign * volume . OrderData Represents order data for a specific ticker. SH market provide canceling in OrderData with order_type='D' , FilterMode.no_cancel is used to filter canceling. Properties : - ticker : str The ticker symbol for the order data. - timestamp : float The timestamp of the order data. - price : float The price at which the order placed. - volume : float | None The volume of the order. - side : TransactionSide The side of the order (buy or sell, side.order_sign 1 or -1). - OrderType : OrderType ## check here - order_id : int | str Order id, associated with buy_id or sell_id in TransactionData . OrderBook Represents order book for a specific ticker. Properties : - ticker : str The ticker symbol for the order book. - timestamp : float The timestamp of the order book. - mid_price : float (ask1 price + bid1 price)/2 - spread : float ask1 price - bid1 price - spread_pct : float spread / mid_price - bid : Book - ask : Book Book have property price and volume , which are list[float] . - best_bid_price : float - best_bid_volume : float bid1 price and volume. - best_ask_price : float - best_ask_volume : float ask1 price and volume.","title":"Data Fields"},{"location":"factor/data_fields/#available-data-fields","text":"There are four frequently used subclass of MarketData . - TickData - TransactionData | TradeData - OrderData - OrderBook","title":"Available data fields"},{"location":"factor/data_fields/#tickdata","text":"Represents tick data for a specific ticker. Properties : - ticker : str The ticker symbol for the tick data. - timestamp : float The timestamp of the tick data - bid : list[list[float | int]] | None A list of bid prices and volumes. Optional, used to build the order book. - ask : list[list[float | int]] | None A list of ask prices and volumes. Optional, used to build the order book. - level_2 : OrderBook | None The level 2 order book created from the bid and ask data. - order_book : OrderBook | None Alias for level_2 . - last_price : float The last traded price. - bid_price : float | None The bid1 price. - ask_price : float | None The ask1 price. - bid_volume : float | None The bid1 volume. - ask_volume : float | None The ask1 volume. - total_traded_volume : float The total traded volume, accumulated from opening. - total_traded_notional : float The total traded notional value, accumulated from opening. - total_trade_count : float The total number of trades, accumulated from opening. - mid_price : float The midpoint price calculated as the average of bid and ask prices. - market_price : float The last traded price.","title":"TickData"},{"location":"factor/data_fields/#transactiondata-tradedata","text":"TransactionData represents transaction data for a specific ticker. TradeData allows initialization with trade_price instead of price and trade_volume instead of volume . It provides additional alias properties for these alternate names. SZ market provide canceling in TradeData with price , notional , side.sign , either buy_id or sell_id = 0, FilterMode.no_cancel is used to filter canceling. Properties : - ticker : str The ticker symbol for the transaction data. - timestamp : float The timestamp of the transaction data. - price : float The price at which the transaction occurred. - volume : float | None The volume of the transaction. - side : TransactionSide The side of the transaction (buy, sell or cancel, side.sign 1, -1, 0). - multiplier : float The multiplier for the transaction. - transaction_id : int | str | None The identifier for the transaction. - buy_id : int | str | None The identifier for the buying transaction. - sell_id : int | str | None The identifier for the selling transaction. - notional : float The notional value of the transaction. - market_price : float Alias for price . - flow : float The flow of the transaction, calculated as side.sign * volume .","title":"TransactionData | TradeData"},{"location":"factor/data_fields/#orderdata","text":"Represents order data for a specific ticker. SH market provide canceling in OrderData with order_type='D' , FilterMode.no_cancel is used to filter canceling. Properties : - ticker : str The ticker symbol for the order data. - timestamp : float The timestamp of the order data. - price : float The price at which the order placed. - volume : float | None The volume of the order. - side : TransactionSide The side of the order (buy or sell, side.order_sign 1 or -1). - OrderType : OrderType ## check here - order_id : int | str Order id, associated with buy_id or sell_id in TransactionData .","title":"OrderData"},{"location":"factor/data_fields/#orderbook","text":"Represents order book for a specific ticker. Properties : - ticker : str The ticker symbol for the order book. - timestamp : float The timestamp of the order book. - mid_price : float (ask1 price + bid1 price)/2 - spread : float ask1 price - bid1 price - spread_pct : float spread / mid_price - bid : Book - ask : Book Book have property price and volume , which are list[float] . - best_bid_price : float - best_bid_volume : float bid1 price and volume. - best_ask_price : float - best_ask_volume : float ask1 price and volume.","title":"OrderBook"},{"location":"factor/factor_demo/","text":"A factor demo A factor demo is presented in quark-fp/factor_pool/sharpe.py . A typical factor file should include 4 parts: __meta__ : name & params are the most importance two. xxxMonitor & xxxAdaptiveMonitor : class inherited from FactorMonitor and certain type of sampler, which do sampling according to timestamp or volume and implement factor calculation process for stocks. xxxAdaptiveIndexMonitor : class inherited from Synthetic , which composite stock factor to index factor. main : optional, added to run in terminal. We will discuss them in detail. __meta__ __meta__ will be used in scripts in quark-fp\\evaluation\\* . The name and params are used to generate list of FactorMonitor with different params set. comments should be documented to illustrate how the factor is calculated. __meta__ = { 'ver': '0.1.2.alpha3', 'name': 'IntensityAdaptiveIndexMonitor', 'params': [ dict( sampling_interval=5, sample_size=20, name='Monitor.Intensity.Adaptive.Index.0' ), dict( sampling_interval=10, sample_size=20, name='Monitor.Intensity.Adaptive.Index.1' ) ], 'family': 'low-pass', 'market': 'cn', 'requirements': [ 'quark @ git+https://github.com/BolunHan/Quark.git#egg=Quark', # this requirement is not necessary, only put there as a demo 'numpy', # not necessary too, since the env installed with numpy by default 'PyAlgoEngine', # also not necessary ], 'external_data': [], # topic for required external data 'external_lib': [], # other library, like c compiled lib file. 'factor_type': 'basic', 'activated_date': None, 'deactivated_date': None, 'dependencies': [], 'comments': \"\"\" This is a demo for how to properly define a factor. \"\"\" } ArbitrarySampler To use a sampler, a FactorMonitor class must have the following parts inherit and config the sampler Several samplers are provided in quark.factor.sampler , e.g. FixedIntervalSampler , FixedVolumeSampler , VolumeProfileSampler , which are subclass of abstract class MarketDataSampler . To use a certain type of sampler, a factor should inherit from both FactorMonitor and the SamplerClass with needed signature. Additional information about sampler is here . class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def __init__(self, sampling_interval: float, sample_size: int, name: str = 'Monitor.Intensity', monitor_id: str = None): super().__init__(name=name, monitor_id=monitor_id, filter_mode=FilterMode.no_cancel|FilterMode.no_auction) FixedIntervalSampler.__init__(self=self, sampling_interval=sampling_interval, sample_size=sample_size) class IntensityAdaptiveMonitor(IntensityMonitor, VolumeProfileSampler): def __init__(self, sampling_interval: float, sample_size: int = 20, name: str = 'Monitor.Intensity.Adaptive', monitor_id: str = None): super().__init__( sampling_interval=sampling_interval, sample_size=sample_size, name=name, monitor_id=monitor_id ) VolumeProfileSampler.__init__( self=self, sampling_interval=sampling_interval, sample_size=sample_size, profile_type=VolumeProfileType.interval_volume ) register & clear topic When using sampler, some specific topics must be registered with register_sampler method before use in __init__ method. class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def __init__(self, sampling_interval: float, sample_size: int, name: str = 'Monitor.Intensity', monitor_id: str = None): ... self.register_sampler(topic='price', mode=SamplerMode.update) self.register_sampler(topic='notional', mode=SamplerMode.accumulate) self.register_sampler(topic='buy_price', mode=SamplerMode.update) self.register_sampler(topic='buy_notional', mode=SamplerMode.accumulate) self.register_sampler(topic='sell_price', mode=SamplerMode.update) self.register_sampler(topic='sell_notional', mode=SamplerMode.accumulate) clear method should be overridden to re-register topics of the monitor. class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def clear(self): super().clear() # re-register topics self.register_sampler(topic='price', mode=SamplerMode.update) self.register_sampler(topic='notional', mode=SamplerMode.accumulate) self.register_sampler(topic='buy_price', mode=SamplerMode.update) self.register_sampler(topic='buy_notional', mode=SamplerMode.accumulate) self.register_sampler(topic='sell_price', mode=SamplerMode.update) self.register_sampler(topic='sell_notional', mode=SamplerMode.accumulate) hooks and callbacks The process of factor calculation is: 1. MarketData comes 2. filter MarketData if needed with FilterMode 3. accumulate_volume if using volume scale sampler 4. check if timestamp or volume reach next obs in log_obs 5. if reached, enroll the obs in history and calculate factor with on_triggered FilterMode Basic filter for market data. There are 5 enum.auto() types, including no_cancal , no_auction , no_order , no_trade , no_tick . Filters can be added using FilterMode.no_cancal|FilterMode.no_auction in __init__ . class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def __init__(self, sampling_interval: float, sample_size: int, name: str = 'Monitor.Intensity', monitor_id: str = None): super().__init__(name=name, monitor_id=monitor_id, filter_mode=FilterMode.no_cancel | FilterMode.no_auction) accumulate_volume When using volume scale sampler, i.e. FixedVolumeSampler and VolumeProfileSampler , accumulate_volume should be hooked in on_tick_data or on_trade_data , and it doesn't need to be associated with factor calculation. on_trade_data will be more precise than on_tick_data . NOT hook accumulate_volume in on_market_data , volume from tick data will override volume from trade data. class IntensityAdaptiveMonitor(IntensityMonitor, VolumeProfileSampler): def on_trade_data(self, trade_data: TradeData | TransactionData, **kwargs): self.accumulate_volume(market_data=trade_data) log_obs When certain type of MarketData comes, send all registered observations at the same time to the sampler is advised. log_obs can be hooked in either on_xxx_data or on_market_data with filter. class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def on_trade_data(self, trade_data: TradeData | TransactionData, **kwargs): ticker = trade_data.ticker timestamp = trade_data.timestamp price = trade_data.price side = trade_data.side volume = trade_data.volume if side.value == 1: self.log_obs(ticker=ticker, timestamp=timestamp, price=price, notional=price * volume, buy_price=price, buy_notional=price * volume) elif side.value == -1: self.log_obs(ticker=ticker, timestamp=timestamp, price=price, notional=price * volume, sell_price=price, sell_notional=price * volume) else: pass or class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def on_market_data(self, market_data: MarketData, **kwargs): if not isinstance(market_data, TradeData | TransactionData): return ticker = market_data.ticker timestamp = market_data.timestamp price = market_data.price side = market_data.side volume = market_data.volume if side.value == 1: self.log_obs(ticker=ticker, timestamp=timestamp, price=price, notional=price * volume, buy_price=price, buy_notional=price * volume) elif side.value == -1: self.log_obs(ticker=ticker, timestamp=timestamp, price=price, notional=price * volume, sell_price=price, sell_notional=price * volume) else: pass on_triggered Calculate factor in on_triggered and cache the results. All registered topics will call on_triggered , it's advised to filter needed topics in calculation. If other registered topics is needed, can use self.get_history(topic,ticker) to get the data. class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def on_triggered(self, ticker, topic, sampler, **kwargs): if topic == 'buy_price': self._intensity_buy[ticker] = self.calculate_intensity(price=sampler.history.get(ticker)) elif topic == 'sell_price': self._intensity_sell[ticker] = self.calculate_intensity(price=sampler.history.get(ticker)) elif topic == 'price': self._intensity_all[ticker] = self.calculate_intensity(price=sampler.history.get(ticker)) sampler readiness VolumeProfileSampler need fitting for volume prediction model. is_ready property should be overridden with correct readiness flag if using this sampler. class IntensityAdaptiveMonitor(IntensityMonitor, VolumeProfileSampler): @property def is_ready(self) -> bool: return self.profile_ready Synthetic Build the class xxxAdaptiveIndexMonitor to composite stock factor to index factor. This class inherit from the previous class which calculate stock factor and Synthetic from quark.factor.utils . class IntensityAdaptiveIndexMonitor(IntensityAdaptiveMonitor, Synthetic): def __init__(self, sampling_interval: float, sample_size: int, weights: dict[str, float] = None, name: str = 'Monitor.Intensity.Adaptive.Index', monitor_id: str = None): super().__init__( sampling_interval=sampling_interval, sample_size=sample_size, name=name, monitor_id=monitor_id ) Synthetic.__init__(self=self, weights=weights) This class override __call__ to filter MarketData with tick in weights. class IntensityAdaptiveIndexMonitor(IntensityAdaptiveMonitor, Synthetic): def __call__(self, market_data: MarketData, **kwargs): ticker = market_data.ticker if self.weights and ticker not in self.weights: return super().__call__(market_data=market_data, **kwargs) This class must override factor_names to cache factor value, and value with method composite to calculate index factor based on weighted stock factor. Note that .value can be multi-dimension. There are 3 dimension intensity.buy , intensity.sell , intensity.all in the demo. class IntensityAdaptiveIndexMonitor(IntensityAdaptiveMonitor, Synthetic): def factor_names(self, subscription: list[str]) -> list[str]: return [ f'{self.name.removeprefix(\"Monitor.\")}.intensity.buy', f'{self.name.removeprefix(\"Monitor.\")}.intensity.sell', f'{self.name.removeprefix(\"Monitor.\")}.intensity.all' ] @property def value(self) -> dict[str, float]: intensity_b = self._intensity_buy intensity_s = self._intensity_sell intensity_a = self._intensity_all return { 'intensity.buy': self.composite(values=intensity_b), 'intensity.sell': self.composite(values=intensity_s), 'intensity.all': self.composite(values=intensity_a), } There are other things should be noted when designing a FactorMonitor for customized purpose. See here . main The main can be used to validate the factor. The nodes param can be set to validate one factor or multi factors together. The config_overrides param will override config.ini in CWD. Full demo import numpy as np from algo_engine.base import MarketData, TradeData, TransactionData, TickData from quark.base import LOGGER from quark.factor.utils import FilterMode from quark.factor import SamplerMode, Synthetic, FactorMonitor, VolumeProfileSampler, FixedIntervalSampler, VolumeProfileType __meta__ = { 'ver': '0.1.2.alpha3', 'name': 'IntensityAdaptiveIndexMonitor', 'params': [ dict( sampling_interval=5, sample_size=20, name='Monitor.Intensity.Adaptive.Index.0' ), dict( sampling_interval=10, sample_size=20, name='Monitor.Intensity.Adaptive.Index.1' ) ], 'family': 'low-pass', 'market': 'cn', 'requirements': [ 'quark @ git+https://github.com/BolunHan/Quark.git#egg=Quark', # this requirement is not necessary, only put there as a demo 'numpy', # not necessary too, since the env installed with numpy by default 'PyAlgoEngine', # also not necessary ], 'external_data': [], # topic for required external data 'external_lib': [], # other library, like c compiled lib file. 'factor_type': 'basic', 'activated_date': None, 'deactivated_date': None, 'dependencies': [], 'comments': \"\"\" This is a demo for how to properly define a factor. \"\"\" } class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def __init__(self, sampling_interval: float, sample_size: int, name: str = 'Monitor.Intensity', monitor_id: str = None): super().__init__(name=name, monitor_id=monitor_id, filter_mode=FilterMode.no_cancel|FilterMode.no_auction) FixedIntervalSampler.__init__(self=self, sampling_interval=sampling_interval, sample_size=sample_size) self._intensity_buy: dict[str, float] = {} self._intensity_sell: dict[str, float] = {} self._intensity_all: dict[str, float] = {} self.register_sampler(topic='price', mode=SamplerMode.update) self.register_sampler(topic='notional', mode=SamplerMode.accumulate) self.register_sampler(topic='buy_price', mode=SamplerMode.update) self.register_sampler(topic='buy_notional', mode=SamplerMode.accumulate) self.register_sampler(topic='sell_price', mode=SamplerMode.update) self.register_sampler(topic='sell_notional', mode=SamplerMode.accumulate) def on_tick_data(self, tick_data: TickData, **kwargs): x = tick_data.total_traded_notional def on_trade_data(self, trade_data: TradeData | TransactionData, **kwargs): ticker = trade_data.ticker timestamp = trade_data.timestamp price = trade_data.price side = trade_data.side volume = trade_data.volume if side.value == 1: self.log_obs(ticker=ticker, timestamp=timestamp, price=price, notional=price * volume, buy_price=price, buy_notional=price * volume) elif side.value == -1: self.log_obs(ticker=ticker, timestamp=timestamp, price=price, notional=price * volume, sell_price=price, sell_notional=price * volume) else: pass def calculate_intensity(self, price, epsilon: float=1e-8) -> float: price_vector = np.array(price) if len(price_vector) < 3: return np.nan price_vector = price_vector[:-1] price_pct_vector = np.diff(price_vector) / price_vector[:-1] mean = np.mean(price_pct_vector) std = np.std(price_pct_vector) return np.divide(mean, std + epsilon) def on_triggered(self, ticker, topic, sampler, **kwargs): if topic == 'buy_price': self._intensity_buy[ticker] = self.calculate_intensity(price=sampler.history.get(ticker)) elif topic == 'sell_price': self._intensity_sell[ticker] = self.calculate_intensity(price=sampler.history.get(ticker)) elif topic == 'price': self._intensity_all[ticker] = self.calculate_intensity(price=sampler.history.get(ticker)) def factor_names(self, subscription: list[str]) -> list[str]: return [ f'{self.name.removeprefix(\"Monitor.\")}.{ticker}' for ticker in subscription ] def clear(self): super().clear() # re-register topics self.register_sampler(topic='price', mode=SamplerMode.update) self.register_sampler(topic='notional', mode=SamplerMode.accumulate) self.register_sampler(topic='buy_price', mode=SamplerMode.update) self.register_sampler(topic='buy_notional', mode=SamplerMode.accumulate) self.register_sampler(topic='sell_price', mode=SamplerMode.update) self.register_sampler(topic='sell_notional', mode=SamplerMode.accumulate) @property def value(self) -> dict[str, float] | float: return self._intensity_all class IntensityAdaptiveMonitor(IntensityMonitor, VolumeProfileSampler): def __init__(self, sampling_interval: float, sample_size: int = 20, name: str = 'Monitor.Intensity.Adaptive', monitor_id: str = None): super().__init__( sampling_interval=sampling_interval, sample_size=sample_size, name=name, monitor_id=monitor_id ) # for profile_type = VolumeProfileType.interval_volume or VolumeProfileType.accumulative_volume VolumeProfileSampler.__init__( self=self, sampling_interval=sampling_interval, sample_size=sample_size, profile_type=VolumeProfileType.interval_volume ) # for profile_type = VolumeProfileType.simple_online # VolumeProfileSampler.__init__( # self=self, # sampling_interval=sampling_interval, # sample_size=sample_size, # n_window = 100, # profile_type=VolumeProfileType.simple_online # ) def on_trade_data(self, trade_data: TradeData | TransactionData, **kwargs): self.accumulate_volume(market_data=trade_data) super().on_trade_data(trade_data=trade_data, **kwargs) @property def is_ready(self) -> bool: return self.profile_ready class IntensityAdaptiveIndexMonitor(IntensityAdaptiveMonitor, Synthetic): def __init__(self, sampling_interval: float, sample_size: int, weights: dict[str, float] = None, name: str = 'Monitor.Intensity.Adaptive.Index', monitor_id: str = None): super().__init__( sampling_interval=sampling_interval, sample_size=sample_size, name=name, monitor_id=monitor_id ) Synthetic.__init__(self=self, weights=weights) def __call__(self, market_data: MarketData, **kwargs): ticker = market_data.ticker if self.weights and ticker not in self.weights: return super().__call__(market_data=market_data, **kwargs) def factor_names(self, subscription: list[str]) -> list[str]: return [ f'{self.name.removeprefix(\"Monitor.\")}.intensity.buy', f'{self.name.removeprefix(\"Monitor.\")}.intensity.sell', f'{self.name.removeprefix(\"Monitor.\")}.intensity.all' ] @property def value(self) -> dict[str, float]: intensity_b = self._intensity_buy intensity_s = self._intensity_sell intensity_a = self._intensity_all return { 'intensity.buy': self.composite(values=intensity_b), 'intensity.sell': self.composite(values=intensity_s), 'intensity.all': self.composite(values=intensity_a), } def main(): from quark.base import safe_exit from quark_validator.factor.evaluation import FactorTree, FactorNode, eval_tree factor_tree = FactorTree( nodes=[ FactorNode(name='Monitor.Intensity.Adaptive.Index.0', file=__file__), FactorNode(name='Monitor.Intensity.Adaptive.Index.1', file=__file__) ], config_overrides={ 'Datalore': { \"FEE_RATE\": 0.00032, \"ALPHA\": 0.1, \"POLY_DEGREE\": 2, \"Calibration\": { \"pct_change_900\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-10, \"l1\": 0.01, \"l2\": 0.01, \"balanced_label\": True }, \"state_3\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-07, \"l1\": 0.001, \"l2\": 0.001, \"balanced_label\": True }, \"up_actual_3\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-06 }, \"down_actual_3\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-06 }, \"target_actual_3\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-10, \"l1\": 0.0001, \"l2\": 0.0001, \"balanced_label\": True }, \"up_smoothed_3\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-06 }, \"down_smoothed_3\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-06 }, \"target_smoothed_3\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-10, \"l1\": 0.0001, \"l2\": 0.0001, \"balanced_label\": True } } } } ) eval_tree(factor_tree) safe_exit() if __name__ == '__main__': main()","title":"Factor Demo"},{"location":"factor/factor_demo/#a-factor-demo","text":"A factor demo is presented in quark-fp/factor_pool/sharpe.py . A typical factor file should include 4 parts: __meta__ : name & params are the most importance two. xxxMonitor & xxxAdaptiveMonitor : class inherited from FactorMonitor and certain type of sampler, which do sampling according to timestamp or volume and implement factor calculation process for stocks. xxxAdaptiveIndexMonitor : class inherited from Synthetic , which composite stock factor to index factor. main : optional, added to run in terminal. We will discuss them in detail.","title":"A factor demo"},{"location":"factor/factor_demo/#__meta__","text":"__meta__ will be used in scripts in quark-fp\\evaluation\\* . The name and params are used to generate list of FactorMonitor with different params set. comments should be documented to illustrate how the factor is calculated. __meta__ = { 'ver': '0.1.2.alpha3', 'name': 'IntensityAdaptiveIndexMonitor', 'params': [ dict( sampling_interval=5, sample_size=20, name='Monitor.Intensity.Adaptive.Index.0' ), dict( sampling_interval=10, sample_size=20, name='Monitor.Intensity.Adaptive.Index.1' ) ], 'family': 'low-pass', 'market': 'cn', 'requirements': [ 'quark @ git+https://github.com/BolunHan/Quark.git#egg=Quark', # this requirement is not necessary, only put there as a demo 'numpy', # not necessary too, since the env installed with numpy by default 'PyAlgoEngine', # also not necessary ], 'external_data': [], # topic for required external data 'external_lib': [], # other library, like c compiled lib file. 'factor_type': 'basic', 'activated_date': None, 'deactivated_date': None, 'dependencies': [], 'comments': \"\"\" This is a demo for how to properly define a factor. \"\"\" }","title":"__meta__"},{"location":"factor/factor_demo/#arbitrarysampler","text":"To use a sampler, a FactorMonitor class must have the following parts","title":"ArbitrarySampler"},{"location":"factor/factor_demo/#inherit-and-config-the-sampler","text":"Several samplers are provided in quark.factor.sampler , e.g. FixedIntervalSampler , FixedVolumeSampler , VolumeProfileSampler , which are subclass of abstract class MarketDataSampler . To use a certain type of sampler, a factor should inherit from both FactorMonitor and the SamplerClass with needed signature. Additional information about sampler is here . class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def __init__(self, sampling_interval: float, sample_size: int, name: str = 'Monitor.Intensity', monitor_id: str = None): super().__init__(name=name, monitor_id=monitor_id, filter_mode=FilterMode.no_cancel|FilterMode.no_auction) FixedIntervalSampler.__init__(self=self, sampling_interval=sampling_interval, sample_size=sample_size) class IntensityAdaptiveMonitor(IntensityMonitor, VolumeProfileSampler): def __init__(self, sampling_interval: float, sample_size: int = 20, name: str = 'Monitor.Intensity.Adaptive', monitor_id: str = None): super().__init__( sampling_interval=sampling_interval, sample_size=sample_size, name=name, monitor_id=monitor_id ) VolumeProfileSampler.__init__( self=self, sampling_interval=sampling_interval, sample_size=sample_size, profile_type=VolumeProfileType.interval_volume )","title":"inherit and config the sampler"},{"location":"factor/factor_demo/#register-clear-topic","text":"When using sampler, some specific topics must be registered with register_sampler method before use in __init__ method. class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def __init__(self, sampling_interval: float, sample_size: int, name: str = 'Monitor.Intensity', monitor_id: str = None): ... self.register_sampler(topic='price', mode=SamplerMode.update) self.register_sampler(topic='notional', mode=SamplerMode.accumulate) self.register_sampler(topic='buy_price', mode=SamplerMode.update) self.register_sampler(topic='buy_notional', mode=SamplerMode.accumulate) self.register_sampler(topic='sell_price', mode=SamplerMode.update) self.register_sampler(topic='sell_notional', mode=SamplerMode.accumulate) clear method should be overridden to re-register topics of the monitor. class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def clear(self): super().clear() # re-register topics self.register_sampler(topic='price', mode=SamplerMode.update) self.register_sampler(topic='notional', mode=SamplerMode.accumulate) self.register_sampler(topic='buy_price', mode=SamplerMode.update) self.register_sampler(topic='buy_notional', mode=SamplerMode.accumulate) self.register_sampler(topic='sell_price', mode=SamplerMode.update) self.register_sampler(topic='sell_notional', mode=SamplerMode.accumulate)","title":"register &amp; clear topic"},{"location":"factor/factor_demo/#hooks-and-callbacks","text":"The process of factor calculation is: 1. MarketData comes 2. filter MarketData if needed with FilterMode 3. accumulate_volume if using volume scale sampler 4. check if timestamp or volume reach next obs in log_obs 5. if reached, enroll the obs in history and calculate factor with on_triggered FilterMode Basic filter for market data. There are 5 enum.auto() types, including no_cancal , no_auction , no_order , no_trade , no_tick . Filters can be added using FilterMode.no_cancal|FilterMode.no_auction in __init__ . class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def __init__(self, sampling_interval: float, sample_size: int, name: str = 'Monitor.Intensity', monitor_id: str = None): super().__init__(name=name, monitor_id=monitor_id, filter_mode=FilterMode.no_cancel | FilterMode.no_auction) accumulate_volume When using volume scale sampler, i.e. FixedVolumeSampler and VolumeProfileSampler , accumulate_volume should be hooked in on_tick_data or on_trade_data , and it doesn't need to be associated with factor calculation. on_trade_data will be more precise than on_tick_data . NOT hook accumulate_volume in on_market_data , volume from tick data will override volume from trade data. class IntensityAdaptiveMonitor(IntensityMonitor, VolumeProfileSampler): def on_trade_data(self, trade_data: TradeData | TransactionData, **kwargs): self.accumulate_volume(market_data=trade_data) log_obs When certain type of MarketData comes, send all registered observations at the same time to the sampler is advised. log_obs can be hooked in either on_xxx_data or on_market_data with filter. class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def on_trade_data(self, trade_data: TradeData | TransactionData, **kwargs): ticker = trade_data.ticker timestamp = trade_data.timestamp price = trade_data.price side = trade_data.side volume = trade_data.volume if side.value == 1: self.log_obs(ticker=ticker, timestamp=timestamp, price=price, notional=price * volume, buy_price=price, buy_notional=price * volume) elif side.value == -1: self.log_obs(ticker=ticker, timestamp=timestamp, price=price, notional=price * volume, sell_price=price, sell_notional=price * volume) else: pass or class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def on_market_data(self, market_data: MarketData, **kwargs): if not isinstance(market_data, TradeData | TransactionData): return ticker = market_data.ticker timestamp = market_data.timestamp price = market_data.price side = market_data.side volume = market_data.volume if side.value == 1: self.log_obs(ticker=ticker, timestamp=timestamp, price=price, notional=price * volume, buy_price=price, buy_notional=price * volume) elif side.value == -1: self.log_obs(ticker=ticker, timestamp=timestamp, price=price, notional=price * volume, sell_price=price, sell_notional=price * volume) else: pass on_triggered Calculate factor in on_triggered and cache the results. All registered topics will call on_triggered , it's advised to filter needed topics in calculation. If other registered topics is needed, can use self.get_history(topic,ticker) to get the data. class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def on_triggered(self, ticker, topic, sampler, **kwargs): if topic == 'buy_price': self._intensity_buy[ticker] = self.calculate_intensity(price=sampler.history.get(ticker)) elif topic == 'sell_price': self._intensity_sell[ticker] = self.calculate_intensity(price=sampler.history.get(ticker)) elif topic == 'price': self._intensity_all[ticker] = self.calculate_intensity(price=sampler.history.get(ticker))","title":"hooks and callbacks"},{"location":"factor/factor_demo/#sampler-readiness","text":"VolumeProfileSampler need fitting for volume prediction model. is_ready property should be overridden with correct readiness flag if using this sampler. class IntensityAdaptiveMonitor(IntensityMonitor, VolumeProfileSampler): @property def is_ready(self) -> bool: return self.profile_ready","title":"sampler readiness"},{"location":"factor/factor_demo/#synthetic","text":"Build the class xxxAdaptiveIndexMonitor to composite stock factor to index factor. This class inherit from the previous class which calculate stock factor and Synthetic from quark.factor.utils . class IntensityAdaptiveIndexMonitor(IntensityAdaptiveMonitor, Synthetic): def __init__(self, sampling_interval: float, sample_size: int, weights: dict[str, float] = None, name: str = 'Monitor.Intensity.Adaptive.Index', monitor_id: str = None): super().__init__( sampling_interval=sampling_interval, sample_size=sample_size, name=name, monitor_id=monitor_id ) Synthetic.__init__(self=self, weights=weights) This class override __call__ to filter MarketData with tick in weights. class IntensityAdaptiveIndexMonitor(IntensityAdaptiveMonitor, Synthetic): def __call__(self, market_data: MarketData, **kwargs): ticker = market_data.ticker if self.weights and ticker not in self.weights: return super().__call__(market_data=market_data, **kwargs) This class must override factor_names to cache factor value, and value with method composite to calculate index factor based on weighted stock factor. Note that .value can be multi-dimension. There are 3 dimension intensity.buy , intensity.sell , intensity.all in the demo. class IntensityAdaptiveIndexMonitor(IntensityAdaptiveMonitor, Synthetic): def factor_names(self, subscription: list[str]) -> list[str]: return [ f'{self.name.removeprefix(\"Monitor.\")}.intensity.buy', f'{self.name.removeprefix(\"Monitor.\")}.intensity.sell', f'{self.name.removeprefix(\"Monitor.\")}.intensity.all' ] @property def value(self) -> dict[str, float]: intensity_b = self._intensity_buy intensity_s = self._intensity_sell intensity_a = self._intensity_all return { 'intensity.buy': self.composite(values=intensity_b), 'intensity.sell': self.composite(values=intensity_s), 'intensity.all': self.composite(values=intensity_a), } There are other things should be noted when designing a FactorMonitor for customized purpose. See here .","title":"Synthetic"},{"location":"factor/factor_demo/#main","text":"The main can be used to validate the factor. The nodes param can be set to validate one factor or multi factors together. The config_overrides param will override config.ini in CWD.","title":"main"},{"location":"factor/factor_demo/#full-demo","text":"import numpy as np from algo_engine.base import MarketData, TradeData, TransactionData, TickData from quark.base import LOGGER from quark.factor.utils import FilterMode from quark.factor import SamplerMode, Synthetic, FactorMonitor, VolumeProfileSampler, FixedIntervalSampler, VolumeProfileType __meta__ = { 'ver': '0.1.2.alpha3', 'name': 'IntensityAdaptiveIndexMonitor', 'params': [ dict( sampling_interval=5, sample_size=20, name='Monitor.Intensity.Adaptive.Index.0' ), dict( sampling_interval=10, sample_size=20, name='Monitor.Intensity.Adaptive.Index.1' ) ], 'family': 'low-pass', 'market': 'cn', 'requirements': [ 'quark @ git+https://github.com/BolunHan/Quark.git#egg=Quark', # this requirement is not necessary, only put there as a demo 'numpy', # not necessary too, since the env installed with numpy by default 'PyAlgoEngine', # also not necessary ], 'external_data': [], # topic for required external data 'external_lib': [], # other library, like c compiled lib file. 'factor_type': 'basic', 'activated_date': None, 'deactivated_date': None, 'dependencies': [], 'comments': \"\"\" This is a demo for how to properly define a factor. \"\"\" } class IntensityMonitor(FactorMonitor, FixedIntervalSampler): def __init__(self, sampling_interval: float, sample_size: int, name: str = 'Monitor.Intensity', monitor_id: str = None): super().__init__(name=name, monitor_id=monitor_id, filter_mode=FilterMode.no_cancel|FilterMode.no_auction) FixedIntervalSampler.__init__(self=self, sampling_interval=sampling_interval, sample_size=sample_size) self._intensity_buy: dict[str, float] = {} self._intensity_sell: dict[str, float] = {} self._intensity_all: dict[str, float] = {} self.register_sampler(topic='price', mode=SamplerMode.update) self.register_sampler(topic='notional', mode=SamplerMode.accumulate) self.register_sampler(topic='buy_price', mode=SamplerMode.update) self.register_sampler(topic='buy_notional', mode=SamplerMode.accumulate) self.register_sampler(topic='sell_price', mode=SamplerMode.update) self.register_sampler(topic='sell_notional', mode=SamplerMode.accumulate) def on_tick_data(self, tick_data: TickData, **kwargs): x = tick_data.total_traded_notional def on_trade_data(self, trade_data: TradeData | TransactionData, **kwargs): ticker = trade_data.ticker timestamp = trade_data.timestamp price = trade_data.price side = trade_data.side volume = trade_data.volume if side.value == 1: self.log_obs(ticker=ticker, timestamp=timestamp, price=price, notional=price * volume, buy_price=price, buy_notional=price * volume) elif side.value == -1: self.log_obs(ticker=ticker, timestamp=timestamp, price=price, notional=price * volume, sell_price=price, sell_notional=price * volume) else: pass def calculate_intensity(self, price, epsilon: float=1e-8) -> float: price_vector = np.array(price) if len(price_vector) < 3: return np.nan price_vector = price_vector[:-1] price_pct_vector = np.diff(price_vector) / price_vector[:-1] mean = np.mean(price_pct_vector) std = np.std(price_pct_vector) return np.divide(mean, std + epsilon) def on_triggered(self, ticker, topic, sampler, **kwargs): if topic == 'buy_price': self._intensity_buy[ticker] = self.calculate_intensity(price=sampler.history.get(ticker)) elif topic == 'sell_price': self._intensity_sell[ticker] = self.calculate_intensity(price=sampler.history.get(ticker)) elif topic == 'price': self._intensity_all[ticker] = self.calculate_intensity(price=sampler.history.get(ticker)) def factor_names(self, subscription: list[str]) -> list[str]: return [ f'{self.name.removeprefix(\"Monitor.\")}.{ticker}' for ticker in subscription ] def clear(self): super().clear() # re-register topics self.register_sampler(topic='price', mode=SamplerMode.update) self.register_sampler(topic='notional', mode=SamplerMode.accumulate) self.register_sampler(topic='buy_price', mode=SamplerMode.update) self.register_sampler(topic='buy_notional', mode=SamplerMode.accumulate) self.register_sampler(topic='sell_price', mode=SamplerMode.update) self.register_sampler(topic='sell_notional', mode=SamplerMode.accumulate) @property def value(self) -> dict[str, float] | float: return self._intensity_all class IntensityAdaptiveMonitor(IntensityMonitor, VolumeProfileSampler): def __init__(self, sampling_interval: float, sample_size: int = 20, name: str = 'Monitor.Intensity.Adaptive', monitor_id: str = None): super().__init__( sampling_interval=sampling_interval, sample_size=sample_size, name=name, monitor_id=monitor_id ) # for profile_type = VolumeProfileType.interval_volume or VolumeProfileType.accumulative_volume VolumeProfileSampler.__init__( self=self, sampling_interval=sampling_interval, sample_size=sample_size, profile_type=VolumeProfileType.interval_volume ) # for profile_type = VolumeProfileType.simple_online # VolumeProfileSampler.__init__( # self=self, # sampling_interval=sampling_interval, # sample_size=sample_size, # n_window = 100, # profile_type=VolumeProfileType.simple_online # ) def on_trade_data(self, trade_data: TradeData | TransactionData, **kwargs): self.accumulate_volume(market_data=trade_data) super().on_trade_data(trade_data=trade_data, **kwargs) @property def is_ready(self) -> bool: return self.profile_ready class IntensityAdaptiveIndexMonitor(IntensityAdaptiveMonitor, Synthetic): def __init__(self, sampling_interval: float, sample_size: int, weights: dict[str, float] = None, name: str = 'Monitor.Intensity.Adaptive.Index', monitor_id: str = None): super().__init__( sampling_interval=sampling_interval, sample_size=sample_size, name=name, monitor_id=monitor_id ) Synthetic.__init__(self=self, weights=weights) def __call__(self, market_data: MarketData, **kwargs): ticker = market_data.ticker if self.weights and ticker not in self.weights: return super().__call__(market_data=market_data, **kwargs) def factor_names(self, subscription: list[str]) -> list[str]: return [ f'{self.name.removeprefix(\"Monitor.\")}.intensity.buy', f'{self.name.removeprefix(\"Monitor.\")}.intensity.sell', f'{self.name.removeprefix(\"Monitor.\")}.intensity.all' ] @property def value(self) -> dict[str, float]: intensity_b = self._intensity_buy intensity_s = self._intensity_sell intensity_a = self._intensity_all return { 'intensity.buy': self.composite(values=intensity_b), 'intensity.sell': self.composite(values=intensity_s), 'intensity.all': self.composite(values=intensity_a), } def main(): from quark.base import safe_exit from quark_validator.factor.evaluation import FactorTree, FactorNode, eval_tree factor_tree = FactorTree( nodes=[ FactorNode(name='Monitor.Intensity.Adaptive.Index.0', file=__file__), FactorNode(name='Monitor.Intensity.Adaptive.Index.1', file=__file__) ], config_overrides={ 'Datalore': { \"FEE_RATE\": 0.00032, \"ALPHA\": 0.1, \"POLY_DEGREE\": 2, \"Calibration\": { \"pct_change_900\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-10, \"l1\": 0.01, \"l2\": 0.01, \"balanced_label\": True }, \"state_3\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-07, \"l1\": 0.001, \"l2\": 0.001, \"balanced_label\": True }, \"up_actual_3\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-06 }, \"down_actual_3\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-06 }, \"target_actual_3\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-10, \"l1\": 0.0001, \"l2\": 0.0001, \"balanced_label\": True }, \"up_smoothed_3\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-06 }, \"down_smoothed_3\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-06 }, \"target_smoothed_3\": { \"optimizer\": \"SLSQP\", \"tol\": 1e-10, \"l1\": 0.0001, \"l2\": 0.0001, \"balanced_label\": True } } } } ) eval_tree(factor_tree) safe_exit() if __name__ == '__main__': main()","title":"Full demo"},{"location":"factor/factor_metrics/","text":"Intro to factor metrics Validation Process In factor validation, quantile regression is performed for each quantile to draw confidence interval at certain alpha. For a certain alpha (used 0.1), calculate metrics for all , all_up , all_down , selected , selected_up and selected_down of y_val and y_true to test prediction power of the model. Metrics Functions There are 5 types of metrics functions used to evaluate factor utility for every pred_var . Note that y_val and y_true which are 1-d arrays are excepted for these functions. Metrics of Error : MAE (Mean Absolute Error) MSE (Mean Squared Error) Metrics of Accuracy : Acc (Accuracy) Acc_Quantile (Accuracy by Quantile) Metrics of Information : IC (Information Coefficient) IC_Pearson (Pearson Correlation of Information Coefficient) Metrics of Portfolio : Kelly AUC_ROC (Area Under the Curve - Receiver Operating Characteristic): Acc_AUC_ROC (Accuracy AUC ROC) IC_AUC_ROC (Information Coefficient AUC ROC) Metrics File After validation, Quark will generate metric files for each pred_var ending with .metircs.html in target dump dir. Following should be noted: accuracy_baseline Baseline assumes that one already knows the positive and negative distribution of y_true and makes decision based on the majority. e.g. accuracy_baseline for a day with 6:4 or 4:6 pos/neg y_true is 0.6. Accuracy metrics and its AUC-ROC is calculated using raw-baseline. And the accuracy baseline is around 60% and varys in days. Accuracy Confidence Curve & IC Selection Curve For a good factor, its accuracy needs to increase linearly as the confidence level (1-alpha) increases, and when the confidence level is so large that selection ratio is too small, the accuracy is allowed to decrease. A good factor AUC-ROC curve is like:","title":"Factor Metrics"},{"location":"factor/factor_metrics/#intro-to-factor-metrics","text":"","title":"Intro to factor metrics"},{"location":"factor/factor_metrics/#validation-process","text":"In factor validation, quantile regression is performed for each quantile to draw confidence interval at certain alpha. For a certain alpha (used 0.1), calculate metrics for all , all_up , all_down , selected , selected_up and selected_down of y_val and y_true to test prediction power of the model.","title":"Validation Process"},{"location":"factor/factor_metrics/#metrics-functions","text":"There are 5 types of metrics functions used to evaluate factor utility for every pred_var . Note that y_val and y_true which are 1-d arrays are excepted for these functions. Metrics of Error : MAE (Mean Absolute Error) MSE (Mean Squared Error) Metrics of Accuracy : Acc (Accuracy) Acc_Quantile (Accuracy by Quantile) Metrics of Information : IC (Information Coefficient) IC_Pearson (Pearson Correlation of Information Coefficient) Metrics of Portfolio : Kelly AUC_ROC (Area Under the Curve - Receiver Operating Characteristic): Acc_AUC_ROC (Accuracy AUC ROC) IC_AUC_ROC (Information Coefficient AUC ROC)","title":"Metrics Functions"},{"location":"factor/factor_metrics/#metrics-file","text":"After validation, Quark will generate metric files for each pred_var ending with .metircs.html in target dump dir. Following should be noted: accuracy_baseline Baseline assumes that one already knows the positive and negative distribution of y_true and makes decision based on the majority. e.g. accuracy_baseline for a day with 6:4 or 4:6 pos/neg y_true is 0.6. Accuracy metrics and its AUC-ROC is calculated using raw-baseline. And the accuracy baseline is around 60% and varys in days. Accuracy Confidence Curve & IC Selection Curve For a good factor, its accuracy needs to increase linearly as the confidence level (1-alpha) increases, and when the confidence level is so large that selection ratio is too small, the accuracy is allowed to decrease. A good factor AUC-ROC curve is like:","title":"Metrics File"},{"location":"factor/factor_monitor/","text":"Design a Factor Monitor These steps should be noted when designing a FactorMonitor for customized purpose. inheritance, multi-inheritance A factor must inherit from abstract class FactorMonitor in quark.factor.utils . Could inherit from certain samplers class in quark.factor.sampler e.g. FixedIntervalSampler ; Could inherit from EMA and Synthetic in quark.factor.utils to composite and transform stock factor to index factor. signature No kwargs allowed. No advanced data type allowed, only the basic (int/float/str/etc.) and serializable ones (datetime.date is not serializable!) market data filtering Use filter_mode parameter as mentioned in the demo . requesting external data Add 'external' field in the _meta attribute or __meta__ section. External data will be loaded on BoD process, into self.contexts['external'] . factor value caching Register yor return value in factor_name method. Do not hook the calculation process into .value property. Do not assume the .value property even be called. Calculate the indicator / factor value in on_triggered method, if possible. And properly cache the results. .composite() from Synthetic is, however, advised to be called in .value advanced feature: communicate with other factor Use shared memory to communicate with other factor. from quark.base.memory_core import SyncMemoryCore memory_manager = SyncMemoryCore() # to set a value into the shared memory named_vector = memory_manager.register(dtype='NamedVector', name='some_name') named_vector['a'] = 123 # to access the value is just like the same a = named_vector['a'] Each NamedVector can be accessed, from different monitor, as long as they have the same name. there are several available dtypes for the shared memory access. Vector = 'Vector' NamedVector = 'NamedVector' Deque = 'Deque' IntValue = 'IntValue' FloatValue = 'FloatValue' advanced feature: serializing and deserializing Use to_json and update_from_json Note that do not override from_json method. advanced feature: logging and profiling Use quark.base.telemetrics module.","title":"Factor Monitor"},{"location":"factor/factor_monitor/#design-a-factor-monitor","text":"These steps should be noted when designing a FactorMonitor for customized purpose.","title":"Design a Factor Monitor"},{"location":"factor/factor_monitor/#inheritance-multi-inheritance","text":"A factor must inherit from abstract class FactorMonitor in quark.factor.utils . Could inherit from certain samplers class in quark.factor.sampler e.g. FixedIntervalSampler ; Could inherit from EMA and Synthetic in quark.factor.utils to composite and transform stock factor to index factor.","title":"inheritance, multi-inheritance"},{"location":"factor/factor_monitor/#signature","text":"No kwargs allowed. No advanced data type allowed, only the basic (int/float/str/etc.) and serializable ones (datetime.date is not serializable!)","title":"signature"},{"location":"factor/factor_monitor/#market-data-filtering","text":"Use filter_mode parameter as mentioned in the demo .","title":"market data filtering"},{"location":"factor/factor_monitor/#requesting-external-data","text":"Add 'external' field in the _meta attribute or __meta__ section. External data will be loaded on BoD process, into self.contexts['external'] .","title":"requesting external data"},{"location":"factor/factor_monitor/#factor-value-caching","text":"Register yor return value in factor_name method. Do not hook the calculation process into .value property. Do not assume the .value property even be called. Calculate the indicator / factor value in on_triggered method, if possible. And properly cache the results. .composite() from Synthetic is, however, advised to be called in .value","title":"factor value caching"},{"location":"factor/factor_monitor/#advanced-feature-communicate-with-other-factor","text":"Use shared memory to communicate with other factor. from quark.base.memory_core import SyncMemoryCore memory_manager = SyncMemoryCore() # to set a value into the shared memory named_vector = memory_manager.register(dtype='NamedVector', name='some_name') named_vector['a'] = 123 # to access the value is just like the same a = named_vector['a'] Each NamedVector can be accessed, from different monitor, as long as they have the same name. there are several available dtypes for the shared memory access. Vector = 'Vector' NamedVector = 'NamedVector' Deque = 'Deque' IntValue = 'IntValue' FloatValue = 'FloatValue'","title":"advanced feature: communicate with other factor"},{"location":"factor/factor_monitor/#advanced-feature-serializing-and-deserializing","text":"Use to_json and update_from_json Note that do not override from_json method.","title":"advanced feature: serializing and deserializing"},{"location":"factor/factor_monitor/#advanced-feature-logging-and-profiling","text":"Use quark.base.telemetrics module.","title":"advanced feature: logging and profiling"},{"location":"factor/multi_factors/","text":"How to test multi factors quark-fp/evaluation/selection.py can be used to test multi factors. Manual selection of factors Following script validates 2 factors together. - Monitor.Aux.Adaptive.Index.0 of quark-fp/factor_pool/auxiliary.py - Monitor.Intensity.Adaptive.Index.0 of quark-fp/factor_pool/sharpe.py def evaluate(): start_date = datetime.date(2024, 1, 1) end_date = datetime.date(2024, 2, 1) cwd = pathlib.Path(__file__).parent tree = FactorTree() aux_node = FactorTree.get_node( name='Monitor.Aux.Adaptive.Index.0', file=str(pathlib.Path(cwd).parent.joinpath('factor_pool', 'auxiliary.py')) ) tree.append(aux_node) factor_node = FactorTree.get_node( name='Monitor.Intensity.Adaptive.Index.0', file=str(pathlib.Path(cwd).parent.joinpath('factor_pool', 'sharpe.py')) ) tree.append(factor_node) tree.evaluate( override_config={'Datalore.Calibration.l1': 0.001, 'Datalore.Calibration.l2': 0.001}, resume=False, start_date=start_date, end_date=end_date, dtype=['TradeData'], validation_id=f'Simulation.{tree.digest()}', pred_var=list(str(_) for _ in FutureTopic), index_name='000016.SH', pred_target='IH_MAIN', strategy_mode=StrategyMode.sampling, dev_pool=True, override_cache=False ) Note that some config can override config.ini using param override_config . Auto selection of factors Class FactorForest preforms brute-force factor selection, which finally generate best FactorTrees base on metric_weight stored in {target_path}/factor_tree.csv . def run_forest(): start_date = datetime.date(2024, 10, 8) end_date = datetime.date(2024, 10, 18) factor_dir = pathlib.Path(os.getcwd()).parent.joinpath('quark-fp', 'factor_pool') base_pool = None # base_pool = ['sharpe', 'mt_tick', 'oir', 'momentum_bigorder', 'qua', 'voi', 'flow_in'] metrics_weight = {'Acc_Confidence_AUC': 1} ema_alpha = 0.5 n_nodes = 4 branch_per_node = lambda node: 6 - node market = 'cn' index_name = '000016.SH' resume = True override_config = None override_config_all = {\"Datalore.Calibration.pct_change_900.optimizer\": 'Adam', \"Datalore.Calibration.state_3.optimizer\": 'Adam', \"Datalore.Calibration.up_actual_3.optimizer\": 'Adam', \"Datalore.Calibration.down_actual_3.optimizer\": 'Adam', \"Datalore.Calibration.target_actual_3.optimizer\": 'Adam', \"Datalore.Calibration.up_smoothed_3.optimizer\": 'Adam', \"Datalore.Calibration.down_smoothed_3.optimizer\": 'Adam', \"Datalore.Calibration.target_smoothed_3.optimizer\": 'Adam'} dtype = ['TradeData', 'TickData'] dev_pool = True override_cache = False target_path = end_date.strftime('%Y-%m-%d') forest = FactorForest(n_nodes=n_nodes, branch_per_node=branch_per_node) forest.run( factor_dir=factor_dir, base_pool=base_pool, resume=resume, override_config=override_config, override_config_all=override_config_all, start_date=start_date, end_date=end_date, metrics_weight=metrics_weight, ema_alpha=ema_alpha, market=market, dtype=dtype, dev_pool=dev_pool, override_cache=override_cache, index_name=index_name, target_path=target_path ) factor_dir & base_pool are the factor path and files that determine scope of auto selection. metrics_weight is a weighted dict, based on which the overall metrics is calculated. ema_alpha defines how the overall metrics decay over time. n_nodes-1 is the max depth of optimal FactorTree. branch_per_node defines how many FactorTree is retained in certain depth. In the demo, it will be 5 trees in depth1, 4 trees in depth2 and 3 trees in depth3. Optimizer in override_config_all should be tuned to Adam , because Scipy and CVXPY optimizer may fail if dimension of X is too large.","title":"Multi Factors"},{"location":"factor/multi_factors/#how-to-test-multi-factors","text":"quark-fp/evaluation/selection.py can be used to test multi factors.","title":"How to test multi factors"},{"location":"factor/multi_factors/#manual-selection-of-factors","text":"Following script validates 2 factors together. - Monitor.Aux.Adaptive.Index.0 of quark-fp/factor_pool/auxiliary.py - Monitor.Intensity.Adaptive.Index.0 of quark-fp/factor_pool/sharpe.py def evaluate(): start_date = datetime.date(2024, 1, 1) end_date = datetime.date(2024, 2, 1) cwd = pathlib.Path(__file__).parent tree = FactorTree() aux_node = FactorTree.get_node( name='Monitor.Aux.Adaptive.Index.0', file=str(pathlib.Path(cwd).parent.joinpath('factor_pool', 'auxiliary.py')) ) tree.append(aux_node) factor_node = FactorTree.get_node( name='Monitor.Intensity.Adaptive.Index.0', file=str(pathlib.Path(cwd).parent.joinpath('factor_pool', 'sharpe.py')) ) tree.append(factor_node) tree.evaluate( override_config={'Datalore.Calibration.l1': 0.001, 'Datalore.Calibration.l2': 0.001}, resume=False, start_date=start_date, end_date=end_date, dtype=['TradeData'], validation_id=f'Simulation.{tree.digest()}', pred_var=list(str(_) for _ in FutureTopic), index_name='000016.SH', pred_target='IH_MAIN', strategy_mode=StrategyMode.sampling, dev_pool=True, override_cache=False ) Note that some config can override config.ini using param override_config .","title":"Manual selection of factors"},{"location":"factor/multi_factors/#auto-selection-of-factors","text":"Class FactorForest preforms brute-force factor selection, which finally generate best FactorTrees base on metric_weight stored in {target_path}/factor_tree.csv . def run_forest(): start_date = datetime.date(2024, 10, 8) end_date = datetime.date(2024, 10, 18) factor_dir = pathlib.Path(os.getcwd()).parent.joinpath('quark-fp', 'factor_pool') base_pool = None # base_pool = ['sharpe', 'mt_tick', 'oir', 'momentum_bigorder', 'qua', 'voi', 'flow_in'] metrics_weight = {'Acc_Confidence_AUC': 1} ema_alpha = 0.5 n_nodes = 4 branch_per_node = lambda node: 6 - node market = 'cn' index_name = '000016.SH' resume = True override_config = None override_config_all = {\"Datalore.Calibration.pct_change_900.optimizer\": 'Adam', \"Datalore.Calibration.state_3.optimizer\": 'Adam', \"Datalore.Calibration.up_actual_3.optimizer\": 'Adam', \"Datalore.Calibration.down_actual_3.optimizer\": 'Adam', \"Datalore.Calibration.target_actual_3.optimizer\": 'Adam', \"Datalore.Calibration.up_smoothed_3.optimizer\": 'Adam', \"Datalore.Calibration.down_smoothed_3.optimizer\": 'Adam', \"Datalore.Calibration.target_smoothed_3.optimizer\": 'Adam'} dtype = ['TradeData', 'TickData'] dev_pool = True override_cache = False target_path = end_date.strftime('%Y-%m-%d') forest = FactorForest(n_nodes=n_nodes, branch_per_node=branch_per_node) forest.run( factor_dir=factor_dir, base_pool=base_pool, resume=resume, override_config=override_config, override_config_all=override_config_all, start_date=start_date, end_date=end_date, metrics_weight=metrics_weight, ema_alpha=ema_alpha, market=market, dtype=dtype, dev_pool=dev_pool, override_cache=override_cache, index_name=index_name, target_path=target_path ) factor_dir & base_pool are the factor path and files that determine scope of auto selection. metrics_weight is a weighted dict, based on which the overall metrics is calculated. ema_alpha defines how the overall metrics decay over time. n_nodes-1 is the max depth of optimal FactorTree. branch_per_node defines how many FactorTree is retained in certain depth. In the demo, it will be 5 trees in depth1, 4 trees in depth2 and 3 trees in depth3. Optimizer in override_config_all should be tuned to Adam , because Scipy and CVXPY optimizer may fail if dimension of X is too large.","title":"Auto selection of factors"},{"location":"factor/sampler/","text":"Sampler When calculating factors, we always need to do sampling. The most basic sampling is to sample at the same time interval, such as generating candlestick chart; considering that the information density is different on timescale, we can also sample at the same volume or volatility. Currently, Quark provides Sampler on time scale and volume scale, supporting various aggregation modes by SamplerMode . SamplerMode SamplerMode describes how to calculate sampled data from multiple active observations between two snapshots, e.g. price can be update and volume can be accumulate . Supported SamplerMode are: - update - first - accumulate - min - max - median - mean - variance - store : store the raw data, without any calculation SamplerAbstractClass a sampler provides following method: Required: register_sampler(topic, mode) for topic registration Required: log_obs(...) to log and process observation \\ Optional: on_triggered() a callback function for triggered sampler. and some utility function like get_history , get_latest , get_active etc. check the demo for how to use the sampler Temporal Scale Sampler quark.factor.FixedIntervalSampler class quark.factor.FixedIntervalSampler(sampling_interval: float = 1., sample_size: int = 60) Class for a fixed temporal interval sampler. Parameters : - sampling_interval : float Time interval between consecutive samples, in seconds. Default is 1 second. - sample_size : int Number of samples to store in the sampler. Default is 60 samples. Notes : - sampling_interval must be a positive value; otherwise, a warning is issued. - sample_size must be greater than 2 according to Shannon's Theorem. - The sampler is NOT guaranteed to be triggered in a fixed interval, if corresponding market data is missing (e.g. in a melt down event or hit the upper bound limit.) To partially address this issue, subscribe TickData (market snapshot) from exchange and use it to update the sampler. Volume Scale Sampler quark.factor.FixedVolumeIntervalSampler class quark.factor.FixedVolumeIntervalSampler(sampling_interval: float = 100., sample_size: int = 20) Class for a fixed volume interval sampler. Parameters : - sampling_interval : float Volume interval between consecutive samples. Default is 100. - sample_size : int Number of samples to store in the sampler. Default is 20. Methods : accumulate_volume(ticker: str = None, volume: float = 0., market_data: MarketData = None, use_notional: bool = False) Accumulates volume based on market data or explicit ticker and volume, use_notional can be modified. Notes : - The sampling_interval is in shares . - The same fixed volume interval for all ticker. quark.factor.VolumeProfileSampler class quark.factor.VolumeProfileSampler(sampling_interval: float = 60.0, sample_size: int = 20, profile_type: VolumeProfileType = 'simple_online', use_notional: bool = True, **kwargs) Class for adaptive volume interval sampler. Three cases for profile_type profile_type = 'simple_online' Starting from market open, use n_window * sampling_interval seconds of data to estimate a baseline volume for each ticker within sampling_interval seconds, and use the baseline volume for sampling. This method will over-estimate numbers of sampling. Parameters : - sampling_interval : float Target temporal interval between consecutive samples. Default is 60. - sample_size : int Number of samples to store in the sampler. Default is 20. - use_notional : bool Estimate baseline use notional or volume. - n_window : int Number of samples to estimate baseline profile_type = 'accumulative_volume' Before the market opens, a prediction model for the full-day trading volume is established based on the market data of the past several days. Combined with the current market data, a Bayesian update is performed on the full-day trading volume. The sampling volume is determined based on the current time and sampling_interval . Parameters : - sampling_interval : float Target temporal interval between consecutive samples. Default is 60. - sample_size : int Number of samples to store in the sampler. Default is 20. - use_notional : bool Estimate baseline use notional or volume. profile_type = 'interval_volume' Before the market opens, a prediction model for the sampling interval volume is established based on the market data of the past several days. Combined with the current market data, a Bayesian update is performed on the sampling interval volume, which will be used for sampling. Parameters : - sampling_interval : float Target temporal interval between consecutive samples. Default is 60. - sample_size : int Number of samples to store in the sampler. Default is 20. - use_notional : bool Estimate baseline use notional or volume.","title":"Sampler"},{"location":"factor/sampler/#sampler","text":"When calculating factors, we always need to do sampling. The most basic sampling is to sample at the same time interval, such as generating candlestick chart; considering that the information density is different on timescale, we can also sample at the same volume or volatility. Currently, Quark provides Sampler on time scale and volume scale, supporting various aggregation modes by SamplerMode .","title":"Sampler"},{"location":"factor/sampler/#samplermode","text":"SamplerMode describes how to calculate sampled data from multiple active observations between two snapshots, e.g. price can be update and volume can be accumulate . Supported SamplerMode are: - update - first - accumulate - min - max - median - mean - variance - store : store the raw data, without any calculation","title":"SamplerMode"},{"location":"factor/sampler/#samplerabstractclass","text":"a sampler provides following method: Required: register_sampler(topic, mode) for topic registration Required: log_obs(...) to log and process observation \\ Optional: on_triggered() a callback function for triggered sampler. and some utility function like get_history , get_latest , get_active etc. check the demo for how to use the sampler","title":"SamplerAbstractClass"},{"location":"factor/sampler/#temporal-scale-sampler","text":"","title":"Temporal Scale Sampler"},{"location":"factor/sampler/#quarkfactorfixedintervalsampler","text":"class quark.factor.FixedIntervalSampler(sampling_interval: float = 1., sample_size: int = 60) Class for a fixed temporal interval sampler. Parameters : - sampling_interval : float Time interval between consecutive samples, in seconds. Default is 1 second. - sample_size : int Number of samples to store in the sampler. Default is 60 samples. Notes : - sampling_interval must be a positive value; otherwise, a warning is issued. - sample_size must be greater than 2 according to Shannon's Theorem. - The sampler is NOT guaranteed to be triggered in a fixed interval, if corresponding market data is missing (e.g. in a melt down event or hit the upper bound limit.) To partially address this issue, subscribe TickData (market snapshot) from exchange and use it to update the sampler.","title":"quark.factor.FixedIntervalSampler"},{"location":"factor/sampler/#volume-scale-sampler","text":"","title":"Volume Scale Sampler"},{"location":"factor/sampler/#quarkfactorfixedvolumeintervalsampler","text":"class quark.factor.FixedVolumeIntervalSampler(sampling_interval: float = 100., sample_size: int = 20) Class for a fixed volume interval sampler. Parameters : - sampling_interval : float Volume interval between consecutive samples. Default is 100. - sample_size : int Number of samples to store in the sampler. Default is 20. Methods : accumulate_volume(ticker: str = None, volume: float = 0., market_data: MarketData = None, use_notional: bool = False) Accumulates volume based on market data or explicit ticker and volume, use_notional can be modified. Notes : - The sampling_interval is in shares . - The same fixed volume interval for all ticker.","title":"quark.factor.FixedVolumeIntervalSampler"},{"location":"factor/sampler/#quarkfactorvolumeprofilesampler","text":"class quark.factor.VolumeProfileSampler(sampling_interval: float = 60.0, sample_size: int = 20, profile_type: VolumeProfileType = 'simple_online', use_notional: bool = True, **kwargs) Class for adaptive volume interval sampler. Three cases for profile_type profile_type = 'simple_online' Starting from market open, use n_window * sampling_interval seconds of data to estimate a baseline volume for each ticker within sampling_interval seconds, and use the baseline volume for sampling. This method will over-estimate numbers of sampling. Parameters : - sampling_interval : float Target temporal interval between consecutive samples. Default is 60. - sample_size : int Number of samples to store in the sampler. Default is 20. - use_notional : bool Estimate baseline use notional or volume. - n_window : int Number of samples to estimate baseline profile_type = 'accumulative_volume' Before the market opens, a prediction model for the full-day trading volume is established based on the market data of the past several days. Combined with the current market data, a Bayesian update is performed on the full-day trading volume. The sampling volume is determined based on the current time and sampling_interval . Parameters : - sampling_interval : float Target temporal interval between consecutive samples. Default is 60. - sample_size : int Number of samples to store in the sampler. Default is 20. - use_notional : bool Estimate baseline use notional or volume. profile_type = 'interval_volume' Before the market opens, a prediction model for the sampling interval volume is established based on the market data of the past several days. Combined with the current market data, a Bayesian update is performed on the sampling interval volume, which will be used for sampling. Parameters : - sampling_interval : float Target temporal interval between consecutive samples. Default is 60. - sample_size : int Number of samples to store in the sampler. Default is 20. - use_notional : bool Estimate baseline use notional or volume.","title":"quark.factor.VolumeProfileSampler"},{"location":"usage/backtesting/","text":"Backtesting","title":"Backtesting"},{"location":"usage/backtesting/#backtesting","text":"","title":"Backtesting"},{"location":"usage/factor_validation/","text":"How to validate factors Factor validation task is defined in quark_validator/factor/validation.py . A simple validation script is like: import os import datetime import time from quark.factor import IndexWeight from quark.profile import profile_cn_override from quark_validator.factor import validation from factor_pool.sharpe import IntensityAdaptiveIndexMonitor from factor_pool.auxiliary import TrendIndexAdaptiveAuxiliaryMonitor profile_cn_override() # cn trading time etc. os.environ['TZ'] = 'Asia/Shanghai' time.tzset() task = validation.ValidationTask( start_date=datetime.date(2024,1,1), end_date=datetime.date(2024,2,1), index_name='000016.SH', index_weights=IndexWeight(index_name='000016.SH'), dtype=['TickData', 'TransactionData', 'OrderData'], # depend on which types of data are required in factor calculation override_cache=True, # true to re-calculate factor value, otherwise load from database dev_pool=True, # store into dev_pool or prod_pool, must be true validator=validation.InterTemporalValidation, # 2 types, details below factor=[ IntensityAdaptiveIndexMonitor(sampling_interval=10, sample_size=20, weights=validation.INDEX_WEIGHTS, baseline_window=100, aligned_interval=False, name='Monitor.Intensity.Adaptive.Index.1'), IntensityAdaptiveIndexMonitor(sampling_interval=15, sample_size=20, weights=validation.INDEX_WEIGHTS, baseline_window=100, aligned_interval=False, name='Monitor.Intensity.Adaptive.Index.2'), ], # factor monitor instances pred_var=[ 'pct_change_900','state_3', 'up_actual_3','down_actual_3','target_actual_3', 'up_smoothed_3', 'down_smoothed_3','target_smoothed_3' ], # pred_var, details below pred_target='IH_MAIN', sampling_interval=10, # interval in seconds for synthetic index poly_degree=2, # degree of polynomial features for regression analysis training_days=5, # using prior n-day data for model training auxiliary_factor=[ TrendIndexAdaptiveAuxiliaryMonitor(sampling_interval=5,sample_size=20,alpha=0.0739,baseline_window=100,aligned_interval=False,name='Monitor.Aux.Adaptive.Index.0') ] # only used when validator=validation.FactorParamsOptimizer, details below ) task.run() validation.safe_exit(0) Detail about certain params is as below. validator There are 2 options for validator, defined in quark_validator/factor/validation.py : InterTemporalValidation: Model is trained with X = all factor monitors defined in factors with their poly_degree interaction terms. The model uses traning_day days' data prior calibration date. FactorParamsOptimizer: For all factors defined in factors , calculate metrics using cross validation, and select the best parameter set which will be used in the next day. Parameter set is selected based on an ema(alpha=0.5) of previous average metrics. New auxiliary_factor param is used to evaluate factors' incremental effects on metrics beyond aux factors. TrendIndexAdaptiveAuxiliaryMonitor is a momentum factor for fitting factors having no predictive power on trend. pred_var There are 8 basic topics and many extended topics, which are defined in quark/calibration/future.py : pct_change_900 : 900s/60=15min ret state_3 : recursive decoding state of level3 up_actual_3 : up ret of level3 down_actual_3 : down ret of level3 target_actual_3 : up & down ret of level3 up_smoothed_3 : up ret of level3 considered potential loss down_smoothed_3 : down ret of level3 considered potential loss target_smoothed_3 : up & down ret of level3 considered potential loss Extended topics include pct_change_[300|900|1800|3600] , state_[2|3|4] and up_actual_[2|3|4] ... config.ini There are also some validation config can be tuned in sections named after [Datalore] in runtime/config.ini . Different params are allowed for different pred_var , which can be tuned in sub sections. Here are some worth mentioning: l1 & l2 : for regression regularization. optimizer : methods in scipy.optimize.minimize and solvers in CVXPY , and Adam . balanced_label : whether to adjust weight for y_pos and y_neg, available for pct_change_900 , state_3 , target_actual_3 and target_smoothed_3 . avoid_quantile_crossing : true to avoid fitted quantile crossover tol : tolerance for scipy and cvxpy optimizer below are config for Adam : enable_lr_scheduler enable_diagnose lr validation_split patience","title":"Factor Training & Validation"},{"location":"usage/factor_validation/#how-to-validate-factors","text":"Factor validation task is defined in quark_validator/factor/validation.py . A simple validation script is like: import os import datetime import time from quark.factor import IndexWeight from quark.profile import profile_cn_override from quark_validator.factor import validation from factor_pool.sharpe import IntensityAdaptiveIndexMonitor from factor_pool.auxiliary import TrendIndexAdaptiveAuxiliaryMonitor profile_cn_override() # cn trading time etc. os.environ['TZ'] = 'Asia/Shanghai' time.tzset() task = validation.ValidationTask( start_date=datetime.date(2024,1,1), end_date=datetime.date(2024,2,1), index_name='000016.SH', index_weights=IndexWeight(index_name='000016.SH'), dtype=['TickData', 'TransactionData', 'OrderData'], # depend on which types of data are required in factor calculation override_cache=True, # true to re-calculate factor value, otherwise load from database dev_pool=True, # store into dev_pool or prod_pool, must be true validator=validation.InterTemporalValidation, # 2 types, details below factor=[ IntensityAdaptiveIndexMonitor(sampling_interval=10, sample_size=20, weights=validation.INDEX_WEIGHTS, baseline_window=100, aligned_interval=False, name='Monitor.Intensity.Adaptive.Index.1'), IntensityAdaptiveIndexMonitor(sampling_interval=15, sample_size=20, weights=validation.INDEX_WEIGHTS, baseline_window=100, aligned_interval=False, name='Monitor.Intensity.Adaptive.Index.2'), ], # factor monitor instances pred_var=[ 'pct_change_900','state_3', 'up_actual_3','down_actual_3','target_actual_3', 'up_smoothed_3', 'down_smoothed_3','target_smoothed_3' ], # pred_var, details below pred_target='IH_MAIN', sampling_interval=10, # interval in seconds for synthetic index poly_degree=2, # degree of polynomial features for regression analysis training_days=5, # using prior n-day data for model training auxiliary_factor=[ TrendIndexAdaptiveAuxiliaryMonitor(sampling_interval=5,sample_size=20,alpha=0.0739,baseline_window=100,aligned_interval=False,name='Monitor.Aux.Adaptive.Index.0') ] # only used when validator=validation.FactorParamsOptimizer, details below ) task.run() validation.safe_exit(0) Detail about certain params is as below.","title":"How to validate factors"},{"location":"usage/factor_validation/#validator","text":"There are 2 options for validator, defined in quark_validator/factor/validation.py : InterTemporalValidation: Model is trained with X = all factor monitors defined in factors with their poly_degree interaction terms. The model uses traning_day days' data prior calibration date. FactorParamsOptimizer: For all factors defined in factors , calculate metrics using cross validation, and select the best parameter set which will be used in the next day. Parameter set is selected based on an ema(alpha=0.5) of previous average metrics. New auxiliary_factor param is used to evaluate factors' incremental effects on metrics beyond aux factors. TrendIndexAdaptiveAuxiliaryMonitor is a momentum factor for fitting factors having no predictive power on trend.","title":"validator"},{"location":"usage/factor_validation/#pred_var","text":"There are 8 basic topics and many extended topics, which are defined in quark/calibration/future.py : pct_change_900 : 900s/60=15min ret state_3 : recursive decoding state of level3 up_actual_3 : up ret of level3 down_actual_3 : down ret of level3 target_actual_3 : up & down ret of level3 up_smoothed_3 : up ret of level3 considered potential loss down_smoothed_3 : down ret of level3 considered potential loss target_smoothed_3 : up & down ret of level3 considered potential loss Extended topics include pct_change_[300|900|1800|3600] , state_[2|3|4] and up_actual_[2|3|4] ...","title":"pred_var"},{"location":"usage/factor_validation/#configini","text":"There are also some validation config can be tuned in sections named after [Datalore] in runtime/config.ini . Different params are allowed for different pred_var , which can be tuned in sub sections. Here are some worth mentioning: l1 & l2 : for regression regularization. optimizer : methods in scipy.optimize.minimize and solvers in CVXPY , and Adam . balanced_label : whether to adjust weight for y_pos and y_neg, available for pct_change_900 , state_3 , target_actual_3 and target_smoothed_3 . avoid_quantile_crossing : true to avoid fitted quantile crossover tol : tolerance for scipy and cvxpy optimizer below are config for Adam : enable_lr_scheduler enable_diagnose lr validation_split patience","title":"config.ini"},{"location":"usage/setup/","text":"Setup Environment Pycharm is recommended for remote deployment. On venv_312 Quark is complied and installed in venv_312. Clone Quark-FactorPool from https://github.com/CREO-Quark/Quark-FactorPool bash git clone https://github.com/CREO-Quark/Quark-FactorPool.git SSH to 192.168.3.12 Select venv_312 as remote python interpreter Setup deployment config in Tools -> Deployment -> Configration Setup SSH configuration Setup path mappings, which will automatically sync changes in local and remote path Set work dictionary and config.ini for quark In script quark-fp\\evaluation\\selection.py , debug with setting:","title":"Setup"},{"location":"usage/setup/#setup-environment","text":"Pycharm is recommended for remote deployment.","title":"Setup Environment"},{"location":"usage/setup/#on-venv_312","text":"Quark is complied and installed in venv_312. Clone Quark-FactorPool from https://github.com/CREO-Quark/Quark-FactorPool bash git clone https://github.com/CREO-Quark/Quark-FactorPool.git SSH to 192.168.3.12 Select venv_312 as remote python interpreter Setup deployment config in Tools -> Deployment -> Configration Setup SSH configuration Setup path mappings, which will automatically sync changes in local and remote path Set work dictionary and config.ini for quark In script quark-fp\\evaluation\\selection.py , debug with setting:","title":"On venv_312"}]}